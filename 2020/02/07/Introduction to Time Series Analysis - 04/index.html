<!DOCTYPE html>
<html lang="default">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 3.9.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"yoursite.com","root":"/","scheme":"Gemini","version":"7.7.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="Introduction to Time Series Analysis - 04 This note is for course MATH 545 at McGill University. Lecture 10 - Lecture 12">
<meta name="keywords" content="mathematics,time-series">
<meta property="og:type" content="article">
<meta property="og:title" content="Introduction to Time Series Analysis - 04">
<meta property="og:url" content="http://yoursite.com/2020/02/07/Introduction to Time Series Analysis - 04/index.html">
<meta property="og:site_name" content="Zhenyuan Ma">
<meta property="og:description" content="Introduction to Time Series Analysis - 04 This note is for course MATH 545 at McGill University. Lecture 10 - Lecture 12">
<meta property="og:locale" content="default">
<meta property="og:updated_time" content="2020-02-18T18:06:18.851Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Introduction to Time Series Analysis - 04">
<meta name="twitter:description" content="Introduction to Time Series Analysis - 04 This note is for course MATH 545 at McGill University. Lecture 10 - Lecture 12">

<link rel="canonical" href="http://yoursite.com/2020/02/07/Introduction to Time Series Analysis - 04/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true
  };
</script>

  <title>Introduction to Time Series Analysis - 04 | Zhenyuan Ma</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Zhenyuan Ma</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
  </div>

  <div class="site-nav-right"></div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>Home</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-fw fa-user"></i>About</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>Archives</a>

  </li>
        <li class="menu-item menu-item-links">

    <a href="/links/" rel="section"><i class="fa fa-fw fa-sitemap"></i>links</a>

  </li>
  </ul>

</nav>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block " lang="default">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/02/07/Introduction to Time Series Analysis - 04/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="Zhenyuan Ma">
      <meta itemprop="description" content="Master student in McGill University 
">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhenyuan Ma">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Introduction to Time Series Analysis - 04
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-02-07 14:29:11" itemprop="dateCreated datePublished" datetime="2020-02-07T14:29:11-05:00">2020-02-07</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-02-18 13:06:18" itemprop="dateModified" datetime="2020-02-18T13:06:18-05:00">2020-02-18</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/category/Course-Note/" itemprop="url" rel="index">
                    <span itemprop="name">Course Note</span>
                  </a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h2 id="introduction-to-time-series-analysis---04">Introduction to Time Series Analysis - 04</h2>
<p>This note is for course MATH 545 at McGill University.</p>
<p>Lecture 10 - Lecture 12</p>
<hr>
<a id="more"></a>
<!--Lecture 10-->
<h5 id="estimation-of-mean-mu-and-auto-covariance-function-rhoh-for-stationary-x_t-when-ex_tmu"><strong>Estimation of mean <span class="math inline">\(\mu\)</span> and auto-covariance function <span class="math inline">\(\rho(h)\)</span> for stationary <span class="math inline">\(\{X_t\}\)</span> when <span class="math inline">\(E[X_t]=\mu\)</span></strong></h5>
<p><span class="math inline">\(\hat{\mu}=\bar{X}_{n}=\frac{X_{1}+\cdots+X_{n}}{n}\)</span></p>
<p><span class="math inline">\(E\left[\bar{X}_{n}\right]=\frac{E\left[X_{1}\right]+\cdots+E\left[X_{n}\right]}{n}=\mu\)</span></p>
<p><span class="math inline">\(E\left[\left(\bar{X}_{n}-\mu\right)^{2}\right]=\operatorname{MSE}\left(\bar{X}_{n}\right)=\operatorname{Var}\left(\bar{X}_{n}\right)\)</span></p>
<p><span class="math inline">\(\begin{aligned} \operatorname{Var}\left(\bar{X}_{n}\right) &amp;=\operatorname{Var}\left(\frac{1}{n}\left[X_{1}+\cdots +X_{n}\right]\right) \\ &amp;=\frac{1}{n^{2}} \text{Var} \left(X_{1}+\cdots+X_{n}\right) \\ &amp;=\frac{1}{n^{2}} \sum_{i=1}^{n} \sum_{j=1}^{n}\text{Cov}\left(X_{i}, X_{j}\right) \\ &amp;=\frac{1}{h^{2}} \sum_{i=1}^{n} \sum_{j=1}^{n} \gamma(i-j) \\ &amp;=\frac{1}{n^{2}} \sum_{h=-n}^{n}(n-|h|) \gamma(h) \\ &amp;=\frac{1}{n} \sum_{h=-n}^{n}\left(1-\frac{|h|}{n}\right) \gamma(h) \end{aligned}\)</span></p>
<p>(Note that here <span class="math inline">\((n-|h|)\)</span> is the number of possible observed lags. And we have <span class="math inline">\(0\leq |i-j| \leq n\)</span> which means <span class="math inline">\(n+1\)</span> values of <span class="math inline">\(|i-j|\)</span>)</p>
<p>If <span class="math inline">\(\gamma(h) \rightarrow 0\)</span> as <span class="math inline">\(n \rightarrow \infty\)</span>, then <span class="math inline">\(\operatorname{Var}\left(\bar{X}_{n}\right)=\operatorname{MSE}\left(\bar{X}_{n}\right) \rightarrow\)</span> as <span class="math inline">\(n \rightarrow \infty\)</span></p>
<p>If <span class="math inline">\(\sum_{h=-\infty}^{\infty}|\gamma(h)|&lt;\infty\)</span>, then <span class="math inline">\(\lim _{n \rightarrow \infty} n \operatorname{Var}\left(\bar{X}_{n}\right)=\sum_{n=-\infty}^{\infty}|\gamma(h)|\)</span></p>
<p>If <span class="math inline">\(\{X_t\}\)</span> are also Gaussian, then <span class="math inline">\(\bar{X}_{n} \sim N\left(\mu, \frac{1}{n} \sum_{|h|&lt;\infty}\left(1-\frac{|h|}{n}\right) \gamma(h)\right)\)</span></p>
<p>To do testing and identical estimation <span class="math inline">\(\bar{X}_{n} \pm Z_{Q / 2} \frac{\sqrt{\Gamma}}{\sqrt{n}}\)</span>, where <span class="math inline">\(\Gamma = \sum_{|h| &lt; \infty} \gamma(h)\)</span></p>
<p>Plugin <span class="math inline">\(\hat{\Gamma}=\sum_{|h|}\hat{\gamma}(h)\)</span></p>
<p>Example: AR(1) process</p>
<p>Let <span class="math inline">\(\{X_t\}\)</span> be defined by <span class="math inline">\(X_t - \mu = \phi(X_{t-1}-\mu) + Z_t\)</span> where <span class="math inline">\(|\phi| &lt; 1\)</span> and <span class="math inline">\(\{Z_t\}\sim WN(0, \sigma^2)\)</span></p>
<p>So, <span class="math inline">\(\begin{aligned} \Gamma &amp;=\sum_{|h| &lt; \infty} \gamma(h) = \sum_{|h| &lt; \infty} \frac{\sigma^2 \phi^{|h|}}{1-\phi^2} \\ &amp;=(1+2\sum^{\infty}_{h=1} \phi^{|h|})\frac{\sigma^2}{1-\phi^2} \\ &amp;=(1+2\frac{\phi}{1-\phi})\frac{\sigma^2}{1-\phi^2} \\ &amp;=\frac{1-\phi+2\phi}{1-\phi}\frac{\sigma^2}{(1+\phi)(1-\phi)} \\ &amp;=\frac{\sigma^2}{(1-\phi)^2} \end{aligned}\)</span></p>
<p>So 95% Confidence Interval for <span class="math inline">\(\mu\)</span>:</p>
<p><span class="math inline">\(\bar{X}_n \pm \frac{1.96}{\sqrt{n}}\frac{\sigma}{\sqrt{(1-\phi)^2}} = \bar{X}_n \pm \frac{1.96}{\sqrt{n}}\frac{\sigma}{|1-\phi|}\)</span></p>
<p><span class="math inline">\(\hat{\gamma}(h)=\frac{1}{n}\sum_{t=1}^{n-|h|}(X_{t+|h|}-\bar{X}_n)(X_t-\bar{X}_n)\)</span></p>
<p><span class="math inline">\(\hat{\rho}(h)=\frac{\hat{\gamma}(h)}{\hat{\gamma}(0)}\)</span></p>
<p>Both <u>biased</u> in finite samples, but consistent</p>
<p>$_k = $</p>
<p>For all <span class="math inline">\(k&lt;n\)</span>, <span class="math inline">\(\hat{\Gamma}_k\)</span> will be non-negative definite. Not obvious how to estimate for <span class="math inline">\(k\geq n\)</span>, even for <span class="math inline">\(k\)</span> close to <span class="math inline">\(n\)</span>, <span class="math inline">\(\hat{\Gamma}\)</span> will be unstable.</p>
<p>(Jenkin's rule &amp; theorems: need <span class="math inline">\(n=50\)</span> and <span class="math inline">\(h\leq \frac{n}{4}\)</span>)</p>
<p>In large samples without large lags, can approximate the distribution of <span class="math inline">\((\hat{\rho}(1), \cdots, \hat{\rho}(k))\)</span> by:</p>
<p><span class="math display">\[\hat{\rho} \sim MVN(\rho, \frac{1}{n}W)\]</span></p>
<p>where <span class="math inline">\(W\)</span> is a <span class="math inline">\(k\times k\)</span> covariance matrix with elements computed by a simplification of butlet's formula:</p>
<p><span class="math inline">\(w_{ij}=\sum^\infty_{k=1}\{\rho(k+i)+\rho(k-i)-2\rho(k)\rho(i)\}\times\{\rho(k+j)+\rho(k-j)-2\rho(k)\rho(j)\}\)</span></p>
<p><strong><u>Example</u></strong></p>
<p><span class="math inline">\(\{X_t\}\)</span> iid <span class="math inline">\(\Rightarrow\)</span> <span class="math inline">\(\rho(0)=1\)</span> and <span class="math inline">\(\rho(h)=0 \quad |h|&gt;1\)</span></p>
<p>So <span class="math inline">\(w_{ij}=\sum^\infty_{k=1}\rho(k-i)\rho(k-j)\)</span></p>
<p>We have <span class="math inline">\(w_{ii}=1\)</span> and <span class="math inline">\(w_{ij}=0\)</span>, so <span class="math inline">\(\hat{\rho}(h) \sim N(0, \frac{1}{n})\)</span> as <span class="math inline">\(W=I\)</span></p>
<p>We have an MA(1) process with <span class="math inline">\(X_t=Z_t+\theta Z_{t-1}\)</span> where <span class="math inline">\(Z_t \sim WN(0, \sigma^2)\)</span></p>
<p>Then <span class="math inline">\(X_t=\sum^\infty_{k=0}\psi_k Z_{t-k}\)</span> and</p>
<p><span class="math inline">\(\Rightarrow \psi_k = \begin{cases} 1, \text{for } k=0 \\ \theta, \text{for } k=1 \\ 0, \text{for } k\neq\{0, 1\} \end{cases}\)</span></p>
<p>So <span class="math inline">\(\gamma_X(h)=\sum^\infty_{j=-\infty} \psi_j \psi_{j-h}\sigma^2 = \begin{cases}(1+\theta^2)\sigma^2, \text{for } h=0 \\ \theta\sigma^2, \text{for } h=1 \\ 0, \text{for } h\geq 2 \end{cases}\)</span></p>
<!--Lecture 11-->
<p>So <span class="math inline">\(\rho(0) = 1\)</span> and <span class="math inline">\(\rho(\pm 1) = \frac{\gamma(1)}{\gamma(0)} = \frac{\theta}{1+\theta^2}\)</span></p>
<p>From the formula <span class="math inline">\(w_{ij}=\sum^\infty_{k=1}\{\rho(k+i)+\rho(k-i)-2\rho(k)\rho(i)\}\times\{\rho(k+j)+\rho(k-j)-2\rho(k)\rho(j)\}\)</span>, we have for <span class="math inline">\(i=j\)</span></p>
<p><span class="math inline">\(w_{ii}=\sum^\infty_{k=1}\{\rho(k+i)+\rho(k-i)-2\rho(k)\rho(i)\}^2\)</span></p>
<p><span class="math inline">\(w_{11}=(\rho(o)-2\rho(1))^2 + \rho(1)^2 = 1-3\rho(1)^2+4\rho(1)^4\)</span></p>
<p>If it is the case of MA(1), <span class="math inline">\(\hat{\rho}(1) \sim N(\frac{\theta}{1+\theta^2}, \frac{1}{n}(1-3\rho(1)^2+4\rho(1)^4))\)</span></p>
<p>For <span class="math inline">\(i&gt;1\)</span>, <span class="math inline">\(w_{ii}=\sum^\infty_{k=1}\{\rho(k+i)+\rho(k-i)-2\rho(k)\rho(i)\}^2 \\=\rho(0)^2 + \rho(1)^2 + \rho(-1)^2 = 1+2\rho(1)^2\)</span></p>
<p>(Note: because in this case, <span class="math inline">\(\rho(k+i)\)</span> is always 0, <span class="math inline">\(\rho(k)\rho(i)\)</span> is always 0, <span class="math inline">\(\rho(k-i)\)</span> is nonzero only when <span class="math inline">\(k = i, i+1, i-1\)</span>)</p>
<h5 id="prediction-forecasting"><strong>Prediction (Forecasting)</strong></h5>
<p>Goal: Find linear construction of <span class="math inline">\(X_1, \cdots, X_n\)</span> that forecasts <span class="math inline">\(X_{n+h}\)</span> with minimum MSE</p>
<p>Assume best linear predictor of <span class="math inline">\(X_{n+h}\)</span> is:</p>
<p><span class="math inline">\(P_nX_{n+h} = a_0+a_1X_n+a_2X_{n-1}+\cdots+a_nX_1\)</span></p>
<p>We want to find <span class="math inline">\(a_0, a_1, \cdots, a_n\)</span> to minimize:</p>
<p><span class="math inline">\(S(a_0, a_1, \cdots, a_n) = E[(X_{n+h} - (a_0+a_1X_n+a_2X_{n-1}+\cdots+a_nX_1))^2]\)</span></p>
<p><span class="math inline">\(S\)</span> is quadratic, bounded below by zero, and there exist at least one solution to <span class="math inline">\(\frac{\partial}{\partial a_j}S(a_0, \cdots, a_n)=0\)</span> for <span class="math inline">\(j = 0, 1, \cdots, n\)</span></p>
<p>By taking derivatives, it gives (assuming interchange <span class="math inline">\(\frac{\partial}{\partial a_j}\)</span> and <span class="math inline">\(E[\cdot]\)</span> safely)</p>
<p><span class="math display">\[[1]\begin{equation}\frac{\partial}{\partial a_0}S(a_0, \cdots, a_n)=0 \Rightarrow E[X_{n+h} - a_0 - \sum^n_{i=1}a_iX_{n+1-i}]=0 \end{equation}\]</span></p>
<p><span class="math display">\[[2]\begin{equation}\frac{\partial}{\partial a_j}S(a_0, \cdots, a_n)=0 \Rightarrow E[(X_{n+h} - a_0 - \sum^n_{i=1}a_iX_{n+1-i})X_{n+1-j}]=0 \end{equation}\]</span></p>
<p>From equation 1 we have:</p>
<p><span class="math inline">\(a_0 = E(X_{n+h}) - \sum_{i=1}^n a_i E(X_{n+1-i}) \\=\mu-\mu \sum^n_{i=1} a_i\)</span> if <span class="math inline">\(\{X_t\}\)</span> is stationary</p>
<p>Plug it into equation 2, we have:</p>
<p><span class="math inline">\(E[(X_{n+h} - \mu(1-\sum^n_{i=1} a_i) - \sum^n_{i=1}a_iX_{n+1-i})X_{n+1-j}] = 0\)</span></p>
<p><span class="math inline">\(E[(X_{n+h}-\mu)X_{n+1-j}]=E[\sum^n_{i=1}a_i(X_{n+1-i}-\mu)X_{n+1-j}]\)</span></p>
<p><span class="math inline">\(\gamma(h+j-1) = \sum^n_{i=1}a_i E[(X_{n+h}-\mu)X_{n+1-j}] = \sum^n_{i=1}a_i \gamma(i-j)\)</span></p>
<p>We have a matrix form of this formula <span class="math inline">\(\Gamma_n\underset{\sim}{a_n} = \underset{\sim}{\gamma_n}(h)\)</span> where <span class="math inline">\((\Gamma_n)_{ij} = \gamma(i-j)\)</span></p>
<p>Therefore <span class="math inline">\(P_nX_{n+h} = \mu + \sum^n_{i=1}a_i(X_{n+1-i}-\mu)\)</span> where <span class="math inline">\(\underset{\sim}{a_n}\)</span> satisfies <span class="math inline">\(\Gamma_n\underset{\sim}{a_n} = \underset{\sim}{\gamma_n}(h)\)</span>.</p>
<p>Obviously, <span class="math inline">\(E[X_{n+h} - (\mu + \sum^n_{i=1}a_i(X_{n+1-i}-\mu))] = 0\)</span></p>
<p><span class="math inline">\(\begin{align}MSE &amp;=E((X_{n+h} - P_nX_{n+h})^2) \\&amp;=E(X_{n+h} - (\mu + \sum^n_{i=1}a_i(X_{n+1-i}-\mu))^2) \\&amp;=E[((X_{n+h} - \mu) -( \sum^n_{i=1}a_i(X_{n+1-i}-\mu)))^2] \\&amp;=E((X_{n+h} - \mu)^2) -2E((X_{n+h} - \mu)(\sum^n_{i=1}a_i(X_{n+1-i}-\mu))) + E((\sum^n_{i=1}a_i(X_{n+1-i}-\mu))^2) \\&amp;=\gamma(0) - 2\sum^n_{i=1} E((X_{n+h}-\mu)(X_{n+1-i}-\mu))+\sum^n_{i=1}\sum^n_{j=1}a_iE((X_{n+1-i}-\mu)(X_{n+1-j}-\mu))a_j \\&amp;=\gamma(0) - w\sum^n_{i=1}a_i\gamma(h+i-1) + \sum^n_{i=1}\sum^n_{j=1}a_i\gamma(i-j)a_j \\&amp;=\gamma(0) - w\sum^n_{i=1}a_i\gamma(h+i-1) + \sum^n_{i=1}a_i(\sum^n_{j=1}\gamma(i-j)a_j) \\&amp;=\gamma(0) - 2\underset{\sim}{a_n}^T\underset{\sim}{\gamma_n}(h) + \underset{\sim}{a_n}^T\Gamma_n\underset{\sim}{a_n} \\&amp;=\gamma(0) - \underset{\sim}{a_n}^T\underset{\sim}{\gamma_n}(h) \end{align}\)</span></p>
<p>(Note: because <span class="math inline">\(\underset{\sim}{a_n}\)</span> satisfies <span class="math inline">\(\Gamma_n\underset{\sim}{a_n} = \underset{\sim}{\gamma_n}(h)\)</span>, so <span class="math inline">\(\underset{\sim}{a_n}^T\underset{\sim}{\gamma_n}(h) = \underset{\sim}{a_n}^T\Gamma_n\underset{\sim}{a_n}\)</span> )</p>
<!--Lecture 12-->
<p><strong><u>Example</u> AR(1)</strong></p>
<p><span class="math inline">\(X_t = \phi X_{t-1} + Z_t\)</span>, where <span class="math inline">\(|\phi|&lt;1\)</span> and <span class="math inline">\(\{Z_t\} \sim WN(0, \sigma^2)\)</span></p>
<p>We try <span class="math inline">\(a_1=\phi, a_k = 0\)</span> for <span class="math inline">\(k = 2, \cdots, n\)</span></p>
<p>A solution that works is <span class="math inline">\(\underset{\sim}{a_n} = (\phi, 0, \cdots, 0)\)</span> and <span class="math inline">\(P_nX_{n+1} = \underset{\sim}{a_n}^T\underset{\sim}{X_n} = \phi X_n\)</span></p>
<p><span class="math inline">\(E((X_{n+1} - P_nX_{n+1})^2) = \gamma(0) - \underset{\sim}{a_n}^T \underset{\sim}{\gamma}(1) \\=\frac{\sigma^2}{1-\phi^2} - \phi\gamma(1) =\frac{\sigma^2}{1-\phi^2} - \phi\frac{\sigma^2\phi}{1-\phi^2} \\= \sigma^2\)</span></p>
<p>Now let <span class="math inline">\(Y\)</span> and <span class="math inline">\(W_1, \cdots, W_n\)</span> be any random variabe with finite second moments and means <span class="math inline">\(\mu = E(Y)\)</span> and <span class="math inline">\(\mu_i = E(W_i)\)</span>, and covariance <span class="math inline">\(Cov(Y, Y), Cov(Y, W_i), Cov(W_i, W-j)\)</span></p>
<p>Let <span class="math inline">\(\underset{\sim}{W} = (W_n, \cdots, W_1)\)</span>, <span class="math inline">\(\underset{\sim}{\mu} = (\mu_n, \cdots, \mu_1)\)</span>, and <span class="math inline">\(\underset{\sim}{\gamma} = Cov(Y, \underset{\sim}{W})\)</span>, <span class="math inline">\(\Gamma = Cov(\underset{\sim}{W}, \underset{\sim}{W})\)</span> such that <span class="math inline">\(\Gamma_{ij} = Cov(W_{n+1-i}, W_{n+1-j})\)</span></p>
<p>By exactly the same methods from before, we show that the best linear predictor of <span class="math inline">\(Y\)</span> given <span class="math inline">\(W\)</span> is:</p>
<p><span class="math inline">\(P(Y|W) = \mu_Y + \underset{\sim}{a}^T(\underset{\sim}{W} - \underset{\sim}{\mu_W})\)</span></p>
<p>where <span class="math inline">\(\underset{\sim}{a} = (a_1, \cdots, a_n)\)</span> is any solution of <span class="math inline">\(\Gamma\underset{\sim}{a} = \underset{\sim}{\gamma}\)</span></p>
<p>Return to AR(1), assume that we observe <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_3\)</span> but not <span class="math inline">\(X_2\)</span></p>
<p>Let <span class="math inline">\(Y=X_2\)</span> and <span class="math inline">\(W=(X_1, X_3)\)</span>, we have</p>
<p><span class="math inline">\(\Gamma = \begin{pmatrix} \frac{\sigma^2}{1-\phi^2} &amp; \frac{\phi^2\sigma^2}{1-\phi^2}\\ \frac{\phi^2\sigma^2}{1-\phi^2} &amp; \frac{\sigma^2}{1-\phi^2} \end{pmatrix}\)</span></p>
<p><span class="math inline">\(\gamma = \begin{pmatrix} Cov(X_2, X_1) \\ Cov(X_2, X_3) \end{pmatrix} = \begin{pmatrix} \frac{\sigma^2}{1-\phi^2}\phi \\ \frac{\sigma^2}{1-\phi^2}\phi \end{pmatrix}\)</span></p>
<p>As <span class="math inline">\(\Gamma\underset{\sim}{a} = \underset{\sim}{\gamma} \Rightarrow \begin{pmatrix} 1 &amp; \phi^2\\ \phi^2 &amp; 1 \end{pmatrix}\underset{\sim}{a} = \begin{pmatrix} \phi\\ \phi \end{pmatrix}\)</span></p>
<p>So <span class="math inline">\(\underset{\sim}{a} = \begin{pmatrix} \frac{\phi}{1+\phi^2}\\ \frac{\phi}{1+\phi^2} \end{pmatrix}\)</span></p>
<p><span class="math inline">\(P(X_2|X_1, X_3) = \frac{\phi}{1+\phi^2}X_1 + \frac{\phi}{1+\phi^2}X_3 = \frac{\phi}{1+\phi^2}(X_1+X_3) + \frac{\phi}{1+\phi^2}\cdot 0\)</span></p>
<p><span class="math inline">\(P(\cdot|W)\)</span> is a prediction operator and it has useful properties:</p>
<p>Let <span class="math inline">\(E(U^2) &lt; \infty, E(V^2) &lt; \infty, \Gamma=Cov(\underset{\sim}{W}, \underset{\sim}{W})\)</span></p>
<p>Let <span class="math inline">\(\beta, a_1, \cdots, a_n\)</span> be constants</p>
<ol type="1">
<li><span class="math inline">\(P(U|W) = E(U) + a^T(W - E(\underset{\sim}{W}))\)</span> where <span class="math inline">\(\Gamma_\underset{\sim}{a} = Cov(U, \underset{\sim}{W})\)</span></li>
<li><span class="math inline">\(E((U-P(U|\underset{\sim}{W}))\underset{\sim}{W}) = \underset{\sim}{0}\)</span> and <span class="math inline">\(E(U-P(U|\underset{\sim}{W}))=0\)</span></li>
<li><span class="math inline">\(E((U-P(U|\underset{\sim}{W}))^2) = Var(U) - \underset{\sim}{a}^TCov(U, \underset{\sim}{W})\)</span></li>
<li><span class="math inline">\(P(a_iU+a_2V+\beta|W) = a_1P(U|W) + a_2P(V|W)+\beta\)</span></li>
<li><span class="math inline">\(P(\sum_{i=1}^na_iw_i + \beta|\underset{\sim}{W}) = \sum_{i=1}^na_iw_i+\beta\)</span></li>
<li><span class="math inline">\(P(U|\underset{\sim}{W}) = E(U)\)</span> if <span class="math inline">\(Cov(U,\underset{\sim}{W})=0\)</span></li>
<li><span class="math inline">\(P(U|\underset{\sim}{W})=P(P(U|\underset{\sim}{W},\underset{\sim}{V})|\underset{\sim}{W})\)</span></li>
</ol>
<p>(Note: for property 7, <span class="math inline">\(P(U|\underset{\sim}{W}, \underset{\sim}{V})=\mu_U+a_W(W-\mu_W)+a_V(V-\mu_V)\)</span>, <span class="math inline">\(P(U|\underset{\sim}{W}) = P(\mu_U + a_W(W-\mu_W)+a_V(V-\mu_V)|W)\)</span>)</p>
<p>Assume <span class="math inline">\(\{X_t\}\)</span> is a stationary process with mean 0 and auto-covariance function <span class="math inline">\(\gamma(\cdot)\)</span>, we can solve for <span class="math inline">\(\underset{\sim}{a}\)</span> to determine <span class="math inline">\(P_nX_{n+h}\)</span> in terms of <span class="math inline">\(\{X_n, \cdots, X_1\}\)</span>.</p>
<p>However, for large <span class="math inline">\(n\)</span>, inventory <span class="math inline">\(\Gamma\)</span> is not fun!</p>
<p>Perhaps we can use linearity of <span class="math inline">\(P_n\)</span> to do recursive prediction of <span class="math inline">\(P_{n+1}X_{n+h}\)</span> from <span class="math inline">\(P_nX_{n+1}\)</span>.</p>
<p>If <span class="math inline">\(\Gamma_n\)</span> id non-singular, then <span class="math inline">\(P_nX_{n+1} = \underset{\sim}{\phi^T_n}\underset{\sim}{X} = \phi_1X_n + \cdots + \phi_nX_1\)</span></p>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tag/mathematics/" rel="tag"># mathematics</a>
              <a href="/tag/time-series/" rel="tag"># time-series</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2020/01/28/Introduction to Time Series Analysis - 03/" rel="prev" title="Introduction to Time Series Analysis - 03">
      <i class="fa fa-chevron-left"></i> Introduction to Time Series Analysis - 03
    </a></div>
      <div class="post-nav-item">
    <a href="/2020/02/17/Paper List - Traffic Signal Control/" rel="next" title="Paper List - Traffic Signal Control">
      Paper List - Traffic Signal Control <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  

  </div>


          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let activeClass = CONFIG.comments.activeClass;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#introduction-to-time-series-analysis---04"><span class="nav-number">1.</span> <span class="nav-text">Introduction to Time Series Analysis - 04</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#estimation-of-mean-mu-and-auto-covariance-function-rhoh-for-stationary-x_t-when-ex_tmu"><span class="nav-number">1.0.0.1.</span> <span class="nav-text">Estimation of mean \(\mu\) and auto-covariance function \(\rho(h)\) for stationary \(\{X_t\}\) when \(E[X_t]=\mu\)</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#prediction-forecasting"><span class="nav-number">1.0.0.2.</span> <span class="nav-text">Prediction (Forecasting)</span></a></li></ol></li></ol></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Zhenyuan Ma"
      src="/images/avatar.png">
  <p class="site-author-name" itemprop="name">Zhenyuan Ma</p>
  <div class="site-description" itemprop="description">Master student in McGill University 
</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">5</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">2</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">3</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/ZhenyuanMa" title="GitHub → https://github.com/ZhenyuanMa" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:zhenyuan.ma@mail.mcgill.ca" title="E-Mail → mailto:zhenyuan.ma@mail.mcgill.ca" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Zhenyuan Ma</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> v3.9.0
  </div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">Theme – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> v7.7.1
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>
<script src="/js/utils.js"></script><script src="/js/motion.js"></script>
<script src="/js/schemes/pisces.js"></script>
<script src="/js/next-boot.js"></script>



  















  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"/live2dw/assets/wanko.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":true},"react":{"opacity":0.7,"opacityOnHover":0.2},"log":false});</script></body>
</html>
